[
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_01",
    "text": "Urban-MAS: Human-Centered Urban Prediction with LLM-Based Multi-Agent System Shangyu Lou shangyulou@ucsb. edu, slou 4820@sdsu. edu University of California, Santa Barbara & San Diego State University California, USA Abstract Urban Artificial Intelligence(Urban AI)hasadvancedhuman-centered urban tasks such as perception prediction and human dynamics. Large Language Models (LLMs) can integrate multimodal inputs to address heterogeneous data in complex urban systems but often underperformondomain-specifictasks. Urban-MAS, an LLM-based Multi-Agent System (MAS) framework, is introduced for humancenteredurbanpredictionunderzero-shotsettings. Itincludesthree agent types: Predictive Factor Guidance Agents, which prioritize key predictive factors to guide knowledge extraction and enhance theeffecti",
    "section": "unknown",
    "char_start": 0,
    "char_end": 800
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_02",
    "text": "Agents, which prioritize key predictive factors to guide knowledge extraction and enhance theeffectivenessofcompressedurbanknowledgein LLMs; Reliable Urban Info Extraction Agents, which improve robustness by comparing multiple outputs, validating consistency, and re-extracting whenconflictsoccur; and Multi-Urban Info Inference Agents, which integrate extracted multi-source information across dimensions for prediction. Experiments on running-amount prediction and urban perception across Tokyo, Milan, and Seattle demonstrate that Urban-MAS substantially reduces errors compared to single-LLM baselines. Ablation studies indicate that Predictive Factor Guidance Agents are most critical for enhancing predictive performance, positioning Urban-MAS as a scalable paradigm for human-centered urban AI",
    "section": "unknown",
    "char_start": 700,
    "char_end": 1500
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_03",
    "text": "ing predictive performance, positioning Urban-MAS as a scalable paradigm for human-centered urban AI prediction. Code is available on the project website.1 CCS Concepts ‚Ä¢ Computing methodologies ‚Üí Spatial and physical reasoning. Keywords Large Language Models, Urban AI, Multi-Agent System, Humancentered Urban Prediction ACMReference Format: Shangyu Lou.2025.Urban-MAS: Human-Centered Urban Predictionwith LLM-Based Multi-Agent System. In The3rd ACMSIGSPATIALInternational Workshopon Advancesin Urban-AI(Urban AI‚Äô25), November3‚Äì6,2025, Minneapolis, MN, USA. https://doi. org/10.1145/3764926.3771951 1 Introduction Urban AI has played an increasingly important role in addressing diverse urban challenges. Human-centered studies‚Äîsuch as 1https://github. com/THETUREHOOHA/Urban MAS Thisworkislicensedu",
    "section": "unknown",
    "char_start": 1400,
    "char_end": 2200
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_04",
    "text": "nges. Human-centered studies‚Äîsuch as 1https://github. com/THETUREHOOHA/Urban MAS Thisworkislicensedundera Creative Commons Attribution4.0International License. Urban AI‚Äô25, Minneapolis, MN, USA ¬©2025 Copyrightheldbytheowner/author(s). ACMISBN 979-8-4007-2189-2/2025/11 https://doi. org/10.1145/3764926.3771951 urban perception [2, 16, 21] and human dynamics [3], deepening understandingofurbansystemsandsupportevidence-basedpolicymaking to improve quality of life [3, 16, 21]. However, the complexity of urban systems makes selecting and representing predictive features difficult, limiting accuracy [4]. Large Language Models (LLMs)2 have shown strong potential in integrating heterogeneous modalities like text and imagery [4]. However, it remains limited in domain-specific applications [7‚Äì10, 22]",
    "section": "unknown",
    "char_start": 2100,
    "char_end": 2900
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_05",
    "text": "es like text and imagery [4]. However, it remains limited in domain-specific applications [7‚Äì10, 22]. LLMs often compress vast knowledge, making it difficult to model complex domain problems[13,17], andsingle-LLMapproachesstruggletohandlethespecializedandmultifacetedrequirementsofurbantasks[5], leadingto biasedorincompleteoutputsthatmaymisinformpolicymaking. To overcome these limitations, researchers are increasingly adopting MAS [6, 11], where multiple LLM-based agents collaborate. Compared with single LLMs, MAS offers stronger specialization and fault tolerance, mitigating common issues such as hallucinations andinsufficientdomainexpertise[5].Throughdivisionoflaborand collaborative reasoning, MAS demonstrates improved scalability and reasoning ability for complex urban tasks [6]. However",
    "section": "unknown",
    "char_start": 2800,
    "char_end": 3600
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_06",
    "text": "ng, MAS demonstrates improved scalability and reasoning ability for complex urban tasks [6]. However, to the best of knowledge, no prior work has applied MAS approaches to enhance human-centered urban predictions, motivating this work to examine: To what extent do LLM-based multi-agent systems enhance human-centered urban prediction? Existing approaches to enhance single-LLM performance mainly rely on fine-tuning [4, 17, 20], which demands extensive data and computation, or on chain-of-thought (Co T) prompting [14], which requiresmanuallydesignedreasoningchainsthataretime-consuming and labor-intensive. In human-centered urban prediction such as urbanperceptionprediction, muchattentionhasbeengiventoidentifying the most important features that contribute to task accuracy [15]. yet none expli",
    "section": "unknown",
    "char_start": 3500,
    "char_end": 4300
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_07",
    "text": "giventoidentifying the most important features that contribute to task accuracy [15]. yet none explicitly extract the most predictive influential factors to guide LLMs. Given the complexity of cities, determinants spanmultipledimensions(socialandbuiltenvironments)andscales (macro and street levels) [3], making manual identification highly demanding. By contrast, MAS enables parallelized and specialized exploration[1]acrossdimensions, providingamoreautomatic, comprehensive, and efficient way to uncover task-relevant influential factors. While deep-research MAS has shown promise in general AI[1], ithasnotbeenappliedtosystematicallyidentifysuchfactors in human-centered urban prediction. Inaddition, Somestudiesattempttoleveragetask-relatedknowledge compressed within a single LLM [14, 17]. Howe",
    "section": "unknown",
    "char_start": 4200,
    "char_end": 5000
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_08",
    "text": "ion, Somestudiesattempttoleveragetask-relatedknowledge compressed within a single LLM [14, 17]. However, they lack mechanisms to verify and enhance the reliability of extracted information. Biased or inconsistent information, once incorporated into prediction, can cause errors, thereby reduce result reliability. MAS offers the advantages through role allocation and task 2Alsoreferredtoas MLLMs; usedinterchangeablyinthispaper. a r X i v : 2 5 1 1 . 0 0 0 9 6 v 1 [ c s . M A ] 3 0 O c t 2 0 2 5\n\nUrban AI‚Äô25, November3‚Äì6,2025, Minneapolis, MN, USA Shangyu Lou specialization[1, 6], it could enables simultaneous cross-validation and refinement during knowledge extraction, substantially improvingcredibility[5].Nevertheless, thiscapabilityhasyettobeapplied to human-centered urban tasks. To addres",
    "section": "unknown",
    "char_start": 4900,
    "char_end": 5700
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_09",
    "text": "redibility[5].Nevertheless, thiscapabilityhasyettobeapplied to human-centered urban tasks. To address these limitations and explore MAS potential in urban prediction, this study introduces Urban-MAS, a multi-agent system for human-centered urban tasks under zero-shot conditions. Urban-MAS integrates three classes of agents: (1) Predictive Factor Guidance Agents, which collaborate to prioritize influential factors and guide knowledge extraction; (2) Reliable Urban Info Extraction Agents, which improve robustness through multi-output comparison, consistency validation, and re-extraction when conflicts occur; and (3) Multi-Urban Info Inference Agents, which integrate multisource information for prediction. This framework overcomes the constraintsofsingle-LLMmethodsandadvances LLMperformance i",
    "section": "unknown",
    "char_start": 5600,
    "char_end": 6400
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_10",
    "text": "prediction. This framework overcomes the constraintsofsingle-LLMmethodsandadvances LLMperformance in human-centered urban prediction. The main contributions are: ‚Ä¢ Presents the first MAS framework for human-centered urban prediction. Urban-MAS integrates three agent layers to enable prioritized factor selection, reliable urban informationextraction, andintegratedmulti-sourcepredictionunder zero-shot conditions, outperforming single-LLM baselines across metrics. ‚Ä¢ Introduces a MAS-based mechanism to improve the reliability of urban knowledge extraction. Reliable Urban Info Extraction Agents use output comparison, consistency checks, and selective re-extraction to mitigate bias and enhance predictive robustness. ‚Ä¢ Evaluates performance on urban perception and human dynamics prediction acros",
    "section": "unknown",
    "char_start": 6300,
    "char_end": 7100
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_11",
    "text": "edictive robustness. ‚Ä¢ Evaluates performance on urban perception and human dynamics prediction across cities on three continents. Results demonstrate that Urban-MAS achieves efficient, low-cost, and significant zero-shot gains, advancing human-centered Urban AI research. 2 Urban-MAS To enhance LLM performance in human-centered urban research, the Urban-MAS framework comprises three agent layers (Figure 1). Predictive Factor Guidance Agents identify the most relevant predictive factors, guiding extraction and improving the utility of compressed urban knowledge. Reliable Urban Info Extraction Agents enhance stability by generating multiple outputs, checking consistency, and re-extracting when needed to ensure trustworthy information. Multi-Urban Info Inference Agents integrate these refined",
    "section": "unknown",
    "char_start": 7000,
    "char_end": 7800
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_12",
    "text": "needed to ensure trustworthy information. Multi-Urban Info Inference Agents integrate these refined multi-source signals across dimensions and scales to deliver robust, task-specific urban predictions. Predictive Factor Guidance Agents. Urban prediction requires focusing on the most influential factors for each task and data source, as general prompts often yield noisy cues. To address this, the Predictive Factor Guidance Agentslayeremploystargeted Deepresearch subagentsbasedontheopendeepresearchframeworkfrom Lang Chain[12] to generate research-level reports on the most influential factors of the task. Then, the Summary subagents summarize the findings into concise predictive factors, organized by social and environmental dimensions and macro and street levels. Given an urban prediction ta",
    "section": "unknown",
    "char_start": 7700,
    "char_end": 8500
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_13",
    "text": "zed by social and environmental dimensions and macro and street levels. Given an urban prediction taskùúè, the input is the task description. Dimensions are defined as ùê∑ = Social, Built Environmental and levels as ùëÖ = Macro, Street. Foreach (ùëë,ùëü) pairunderthetask, deep-research subagents produce a brief reportùë° ùëë,ùëü containing six key predictive factors, whichsummarysubagentscompressintoapredictivefactor setùëÉ ùëë,ùëü as output, providing dimension- and level-specific guidance for the Urban Info Extraction Agents. Reliable Urban Info Extraction Agents. Urbaninformationfrom a single LLM call is often noisy or inconsistent, weakening inference. To enhance stability, each extraction agent generates two output variants via an Extractor subagent and compares them with an Evaluator subagent. Conflicting",
    "section": "unknown",
    "char_start": 8400,
    "char_end": 9200
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_14",
    "text": "output variants via an Extractor subagent and compares them with an Evaluator subagent. Conflictingfieldsareselectivelyre-extracted bya Refiner subagent. Foreachlocation‚Ñì, fourextractionagentsare alignedtoùëÉ ùëë,ùëü: social-macro, social-street, environment-macro, and environment-street. Candidate outputs are compared by similarity metrics; if agreement exceeds a threshold, one is accepted, otherwise only conflicting fields are regenerated, yielding reliable outputsùëà ùëë,ùëü. This dual-variant and conflict-repair mechanism ensures consistent Urban Info across dimensions and levels, strengthening multi-source integration. Specifically, for each dimension-scale pair, the Evaluator subagent compares two urban information independently generated variants (A and B) from Extractor. The two generated var",
    "section": "unknown",
    "char_start": 9100,
    "char_end": 9900
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_15",
    "text": "o urban information independently generated variants (A and B) from Extractor. The two generated variants are normalized (lowercasing, punctuation removal, whitespace collapsing), and field-level hybrid soft similarity is computed as soft_sim(ùëé,ùëè) =0.4√óJaccard(ùëé,ùëè)+0.6√óSequence Matcher(ùëé,ùëè), (1) where Jaccard[19]measurestokenoverlapand Sequence Matcher[18] capturesphrase-levelalignment. Astabilitythresholdof0.72 isused: if similarity ‚â• 0.72, Variant A is accepted; otherwise, the Refiner regenerates only differing fields. Multi-Urban Info Inference Agents. Urban prediction requires reasoning over complementary Urban Info across social and built dimensions and macro- and street-level scales. Even when each source is reliable, isolated reasoning risks imbalance. To address this, theinferencel",
    "section": "unknown",
    "char_start": 9800,
    "char_end": 10600
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_16",
    "text": "ven when each source is reliable, isolated reasoning risks imbalance. To address this, theinferencelayeremploysan LLM-based Inference Agent that jointly processes the four reliable inputs‚Äîùëà‚àó social, macro,ùëà‚àó social, street, ùëà‚àó environment, macro, and ùëà‚àó environment, street‚Äîto infer task-specific outputs such as running amount or perception scores. The Inference Agent receives the four structured JSON inputs, enforces schema constraints (e. g., {\"running_amount\": 0.0}). As the final Urban MASstage, thislayerintegratesreliableextractiontodeliverrobust, coherent predictions. 3 Experiments Tasks. We evaluate Urban-MAS on two representative humancentered urban prediction tasks: (i) urban perception prediction, focusing on one positive (lively) and one negative (boring) dimension of perception,",
    "section": "unknown",
    "char_start": 10500,
    "char_end": 11300
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_17",
    "text": "on prediction, focusing on one positive (lively) and one negative (boring) dimension of perception, and (ii) human dynamics prediction via running amount estimation. These tasks capture complementary aspects of human‚Äìenvironment interaction by linking perceptual and behavioral responses to urban form. Datasets. Experimentsareconductedon 300 samplesacross Tokyo, Milan, and Seattle, coveringthreecontinentstoassesscross-regional generalizability. For each sampled location, we process the raw geographic coordinates into location text via Open Street Map‚Äôs Nominatim API for reverse geocoding (convert coordinates to address), and further enrich the inputs by querying nearby points of interest using the Overpass API. In addition, street-view imagery is retrieved through the Google Maps API. These",
    "section": "unknown",
    "char_start": 11200,
    "char_end": 12000
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_18",
    "text": "g the Overpass API. In addition, street-view imagery is retrieved through the Google Maps API. These inputs are used as\n\nUrban-MAS: Human-Centered Urban Predictionwith LLM-Based Multi-Agent System Urban AI‚Äô25, November3‚Äì6,2025, Minneapolis, MN, USA Figure 1: Urban-MAS comprises three agent layers: (Left) Predictive Factor Guidance Agents prioritize factor selection; (Middle) Reliable Urban Info Extraction Agentsensurereliableurbaninformationextractionthroughconsistencychecks;(Right)Multi-Urban Info Inference Agentsintegratemulti-sourceurbaninformationforrobusturbanprediction. multi-source data for Urban-MAS across different human-centered tasks. Although the validation dataset is relatively small, its scale is constrained by the cost of collecting and verifying multi-source urban data (str",
    "section": "unknown",
    "char_start": 11900,
    "char_end": 12700
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_19",
    "text": "small, its scale is constrained by the cost of collecting and verifying multi-source urban data (street-view imagery, POI queries), yet remains sufficient for evaluating the quality of the LLM-based solution using several hundred representative examples[5]. For running amount prediction, we use Strava heatmaps , a widely recognized source of physical activity data. Following Le‚Äôs agentbased modeling approach, high-resolution Strava heatmaps were collected for each study area, and raster values were extracted in QGIS at each sampling point. Brightness values, representing running intensity, were rescaled to [0,10]. For urban perception, we adopt Place Pulse 2.0 [21], the largest benchmark of human perceptions of urban environments. Pairwise Google Street View comparisons were aggregated usi",
    "section": "unknown",
    "char_start": 12600,
    "char_end": 13400
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_20",
    "text": "human perceptions of urban environments. Pairwise Google Street View comparisons were aggregated using the True Skill algorithm, yielding continuous perception scores that we rescaled to [0,10]. Models. The experimental setup was designed to evaluate the performance and capabilities of LLM-based multi-agent systems in human-centered urban perception and prediction. All experiments were conducted using GPT-5, a closed-source model representing the state of the art in its class. The exclusive use of LLM-based configurations aims to examine how multi-agent interaction improves efficiency, reasoning, and overall performance compared with a single-LLM baseline, as well as to assess the contribution of each agent component within the MAS framework. The proposed Urban-MAS framework comprises thre",
    "section": "unknown",
    "char_start": 13300,
    "char_end": 14100
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_21",
    "text": "on of each agent component within the MAS framework. The proposed Urban-MAS framework comprises three layers of agents: Predictive Factor Guidance Agents, Reliable Urban Info Extraction Agents, and Multi-Urban Info Inference Agents. The Predictive Factor Guidancelayerleveragestheopendeepresearchframeworkfrom Lang Chain‚Äîrankedsixthonthe Deep Research Bench Leaderboard with GPT-4o‚Äîto ensure consistency and relevance of the extracted predictive factors. The Reliable Urban Info Extraction and Multi Urban Info Inference layers are implemented on GPT-5 in JSON mode using zero-shot prompting, with a single-LLM GPT-5 baseline included for comparison. Evaluation. Performance is assessed using MAE, MSE, and RMSE for continuous outcomes (running amount and perception scores). We also report ablation",
    "section": "unknown",
    "char_start": 14000,
    "char_end": 14800
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_22",
    "text": "E, and RMSE for continuous outcomes (running amount and perception scores). We also report ablation studies to isolate the contributions of factor guidance and reliability enhancement. 3.1 Main Results Table 1 summarizes the performance improvements achieved by the integrated Urban-MAS compared to the baseline single-LLM Table1: Performancegainswith Urban-MASwithsingle LLMacross multipletasks(allmetrics: lowerisbetter). Method MAE MSE RMSE People Running Amount Single LLM 2.99 13.73 3.70 Urban-MAS(Ours) 2.97(‚Üì0.73%) 13.20(‚Üì3.82%) 3.63(‚Üì1.93%) People Urban Perception(Boringness) Single LLM 2.83 9.95 3.15 Urban-MAS(Ours) 2.05(‚Üì27.37%) 5.84(‚Üì41.33%) 2.42(‚Üì23.40%) People Urban Perception(Liveliness) Single LLM 2.69 9.10 3.02 Urban-MAS(Ours) 1.73(‚Üì35.81%) 4.40(‚Üì51.67%) 2.10(‚Üì30.48%) model (GPT-",
    "section": "unknown",
    "char_start": 14700,
    "char_end": 15500
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_23",
    "text": "ess) Single LLM 2.69 9.10 3.02 Urban-MAS(Ours) 1.73(‚Üì35.81%) 4.40(‚Üì51.67%) 2.10(‚Üì30.48%) model (GPT-5). Relative to GPT-5, Urban-MAS achieves substantial reductions across all error metrics for every task, demonstrating its effectiveness in enhancing prediction performance for humancentered urban applications. A closer look at the baseline results further reveals variations in the degree of improvement across task types: in particular, error reductions are more pronounced for the safety perception task than for the running amount prediction task. 3.2 Ablation Study Table 2: Ablationstudyon Predictive Factor Guidanceand Reliable Urban Info Extraction(allmetrics: lowerisbetter). Method Variant MAE MSE RMSE People Running Amount Urban-MAS 2.97 13.20 3.63 -Predictive Factors 4.53(‚Üë52.84%) 26.8",
    "section": "unknown",
    "char_start": 15400,
    "char_end": 16200
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_24",
    "text": "MAE MSE RMSE People Running Amount Urban-MAS 2.97 13.20 3.63 -Predictive Factors 4.53(‚Üë52.84%) 26.80(‚Üë102.98%) 5.18(‚Üë42.47%) -Reliability Boost 2.98(‚Üë0.30%) 13.39(‚Üë1.46%) 3.66(‚Üë0.73%) People Urban Perception(Boringness) Urban-MAS 2.05 5.84 2.42 -Predictive Factors 2.39(‚Üë16.37%) 7.52(‚Üë28.69%) 2.74(‚Üë13.44%) -Reliability Boost 2.29(‚Üë11.52%) 6.98(‚Üë19.45%) 2.64(‚Üë9.29%) People Urban Perception(Liveliness) Urban-MAS 1.73 4.40 2.10 -Predictive Factors 2.54(‚Üë46.89%) 8.09(‚Üë83.79%) 2.84(‚Üë35.57%) -Reliability Boost 2.21(‚Üë28.06%) 6.47(‚Üë47.02%) 2.54(‚Üë21.25%) We conducted an ablation study to evaluate two strategies for improving LLM performance on human-centered urban tasks: (1)\n\nUrban AI‚Äô25, November3‚Äì6,2025, Minneapolis, MN, USA Shangyu Lou Predictive Factor Guidance Agents, which prioritize influent",
    "section": "unknown",
    "char_start": 16100,
    "char_end": 16900
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_25",
    "text": ",2025, Minneapolis, MN, USA Shangyu Lou Predictive Factor Guidance Agents, which prioritize influential predictivefactors, and(2)Reliable Urban Info Extraction Agents, which enhance extraction reliability. As shown in Table 2, the full Urban MAS configuration achieves the lowest errors across all tasks. Removingthe Predictive Factor Guidancemodulecausesalargererror increase than removing the Reliability module, indicating that prioritizingpredictivefactorsismorecritical. Removingthe Predictive Factor Guidance module causes a larger error increase than removing the Reliability module, indicating that prioritizing predictive factors is more critical. Disabling factor prioritization (‚Äú‚ÄìPredictive Factors‚Äù) consistently raises errors, especially in running amount prediction, showing its import",
    "section": "unknown",
    "char_start": 16800,
    "char_end": 17600
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_26",
    "text": "ve Factors‚Äù) consistently raises errors, especially in running amount prediction, showing its importance for modeling activity patterns. Conversely, disabling reliability enhancement (‚Äú‚ÄìReliability Boost‚Äù) increases errors across all tasks, particularly in perception-related dimensions such as liveliness and boringness, highlighting the necessity of reliable urban information extraction. 3.3 Case Study Predictive Factors Agent. Predictivefactorswerederivedthrough an LLM-guided process across two dimensions (social and environmental) and two spatial scales (macro and street level). These structuredfactorsetsserveasmeasurabledescriptorsguidinginformation extraction and inference within Urban-MAS. The complete list of predictors are available on the project website. Urban Info Extraction Agen",
    "section": "unknown",
    "char_start": 17500,
    "char_end": 18300
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_27",
    "text": "AS. The complete list of predictors are available on the project website. Urban Info Extraction Agents. The Reliable Urban Info Extraction Agents Layers extract consistent urban information for each location. When both variants generated from Extractor subagent, the Evaluator subagent confirms stability and retains one version directly. However, when factual discrepancies arise, the Refiner subagent performs conflict-only reconciliation‚Äîregenerating only inconsistentfieldswhilepreservingverifiedones. Thisselectivecorrection ensures factual reliability without redundant regeneration. Detailed examples are available on the project website. 4 Conclusion This paper introduced Urban-MAS, a novel LLM-based multi-agent system for human-centered urban tasks with multi-source data inputs. Urban-MAS",
    "section": "unknown",
    "char_start": 18200,
    "char_end": 19000
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_28",
    "text": "LLM-based multi-agent system for human-centered urban tasks with multi-source data inputs. Urban-MAS integrates automated prioritization of the most predictive factors to guide subsequent knowledge extraction, enhancedreliabilityinextractingurbaninformationfrommulti-source data, andpredictoragentsthatcollaborateunderazero-shotsetting to improve performance on human-centered urban tasks. Experimental results across multiple cities and tasks demonstrate that, compared with single-LLM baselines, Urban-MAS significantly reduces prediction error. Urban-MAS also provides methodological insights: prioritizing the most predictive factors is crucial for enhancing human-centered urban prediction tasks, and improving the reliability of extracting urban knowledge from LLMs is also essential. Future wo",
    "section": "unknown",
    "char_start": 18900,
    "char_end": 19700
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_29",
    "text": ", and improving the reliability of extracting urban knowledge from LLMs is also essential. Future work will extend this framework by incorporating MAS-based automatic optimization of urban prediction performance and applying Urban-MAS to a broader range of urban tasks and larger test samples. References [1] Anthropic.2024. Howwebuiltourmulti-agentresearchsystem. https://www. anthropic. com/engineering/multi-agent-research-system. [2] Ziqi Cuiand Shangyu Lou.2025. Syncperception: AReal-Time Urban Perception Prediction Tool Basedon Graph Neural Networks. In 2025 Annual Modelingand Simulation Conference(ANNSIM). [3] Lin Dong, Hongchao Jiang, Wenjing Li, Bing Qiu, Hao Wang, and Waishan Qiu. 2023. Assessingimpactsofobjectivefeaturesandsubjectiveperceptionsofstreet environmentonrunningamount: Ac",
    "section": "unknown",
    "char_start": 19600,
    "char_end": 20400
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_30",
    "text": ". Assessingimpactsofobjectivefeaturesandsubjectiveperceptionsofstreet environmentonrunningamount: Acasestudyof Boston. Landscapeand Urban Planning 235(2023),104756. [4] Jie Feng, Shengyuan Wang, Tianhui Liu, Yanxin Xi, and Yong Li.2024. Urban LLa VA: AMulti-modal Large Language Modelfor Urban Intelligencewith Spatial Reasoningand Understanding. ar Xivpreprint (2024). ar Xiv:2406.05294 [5] Anna Kalyuzhnaya, Sergey Mityagin, Elizaveta Lutsenko, Andrey Getmanov, Yaroslav Aksenkin, Kamil Fatkhiev, Kirill Fedorin, Nikolay O. Nikitin, Natalia Chichkova, Vladimir Vorona, and Alexander Boukhanovsky.2025. LLMAgents for Smart City Management: Enhancing Decision Support Through Multi-Agent AISystems. Smart Cities8,1(2025),19. [6] Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xua",
    "section": "unknown",
    "char_start": 20300,
    "char_end": 21100
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_31",
    "text": "mart Cities8,1(2025),19. [6] Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, Caiming Xiong, and Shafiq Joty.2025. ASurveyof Frontiersin LLMReasoning: Inference Scaling, Learningto Reason, and Agentic Systems. ar Xivpreprintar Xiv:2504.09037 (2025). [7] Zixuan Keand Bing Liu.2023. Continual Learningof Natural Language Processing Tasks: ASurvey. ar Xiv:2211.12701 [8] Zixuan Ke, Yifei Ming, and Shafiq Joty.2025. NAACL 2025 Tutorial: Adaptation of Large Language Models. ar Xiv:2504.03931[cs. CL] [9] Zixuan Ke, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, and Shafiq Joty. 2025. Demystifying Domain-adaptive Post-training for Financial LLMs. ar Xiv:2501.04961 [10] Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konis",
    "section": "unknown",
    "char_start": 21000,
    "char_end": 21800
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_32",
    "text": "training for Financial LLMs. ar Xiv:2501.04961 [10] Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, and Bing Liu. 2023. Continual Pre-trainingof Language Models. ar Xiv:2302.03241 [11] Zixuan Ke, Austin Xu, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, and Shafiq Joty.2025. MAS-ZERO: Designing Multi-Agent Systemswith Zero Supervision. ar Xivpreprintar Xiv:2505.14996(2025). [12] Lang Chain.2024. Open Deep Research. https://blog. langchain. com/open-deepresearch/. [13] Xinjin Li, Yu Ma, Yangchen Huang, Xingqi Wang, Yuzhen Lin, and Chenxi Zhang. 2024. Synergized Data Efficiencyand Compression(SEC)Optimizationfor Large Language Models. In 20244 th International Conferenceon Electronic Information Engineeringand Computer Science(EIECS). [14] Zongrong Li, Junhao Xu, Siqin Wang, Yif",
    "section": "unknown",
    "char_start": 21700,
    "char_end": 22500
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_33",
    "text": "nic Information Engineeringand Computer Science(EIECS). [14] Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, and Haiyang Li. 2024. Street View LLM: Extracting Geographic Information Usinga Chain-of-Thought Multimodal Large Language Model. ar Xivpreprintar Xiv:2411.14476(2024). [15] Yunzhe Liu, Meixu Chen, Meihui Wang, Jing Huang, Fisher Thomas, Kazem Rahimi, and Mohammad Mamouei. 2023. An interpretable machine learning frameworkformeasuringurbanperceptionsfrompanoramicstreetviewimages. PLOSComputational Biology 19,3(2023), e 1010911. [16] Shangyu Lou, Gabriele Stancato, and Barbara EAPiga.2024. Assessingin-motion urbanvisualperception: analyzingurbanfeatures, designqualities, andpeople‚Äôs perception. In Advances in Representation: New AI-and XR-Driven Transdisciplinarity. Springer,691‚Äì706. [1",
    "section": "unknown",
    "char_start": 22400,
    "char_end": 23200
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_34",
    "text": "ption. In Advances in Representation: New AI-and XR-Driven Transdisciplinarity. Springer,691‚Äì706. [17] Rohin Manvi, Samar Khanna, Gengchen Mai, Marshall Burke, David B. Lobell, and Stefano Ermon.2023. Geo LLM: Extracting Geospatial Knowledgefrom Large Language Models. ar Xivpreprint (2023). ar Xiv:2310.06213 [18] Python Library.[n. d.]. Difflib Python Libaray. https://docs. python. org/3/library/ difflib. html. [19] Gonzalo Travieso, Alexandre Benatti, and Lucianoda F. Costa.2024.An Analytical Approachtothe Jaccard Similarity Index. ar Xivpreprintar Xiv:2410.16436(2024). [20] Yiming Zeng, Wanhao Yu, Zexin Li, Tao Ren, Yu Ma, Jinghan Cao, Xiyan Chen, and Tingting Yu.2025. Bridgingthe Editing Gapin LLMs: Fine Editfor Precise and Targeted Text Modifications. ar Xiv:2502.13358 [21] Fan Zhang,",
    "section": "unknown",
    "char_start": 23100,
    "char_end": 23900
  },
  {
    "source_id": "Lou2025",
    "chunk_id": "chunk_35",
    "text": "Gapin LLMs: Fine Editfor Precise and Targeted Text Modifications. ar Xiv:2502.13358 [21] Fan Zhang, Bolei Zhou, Liu Liu, Yu Liu, Helene H. Fung, Hui Lin, and Carlo Ratti. 2018. Measuringhumanperceptionsofalarge-scaleurbanregionusingmachine learning. Landscapeand Urban Planning 180(2018),148‚Äì160. [22] Sanqiang Zhang, Xinyu Liu, etal.2023. ASurveyon Large Language Models: Applications, Challenges, and Opportunities. ar Xiv preprint ar Xiv:2305.18703 (2023).",
    "section": "unknown",
    "char_start": 23800,
    "char_end": 24600
  }
]